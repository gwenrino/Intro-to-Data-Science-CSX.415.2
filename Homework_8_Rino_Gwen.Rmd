---
title: "COMPSCIX 415.2 Homework 8"
author: "Gwen Rino"
date: "3/21/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, warning=FALSE, message=FALSE}
library(tidyverse)
library(broom)
library(rpart)
library(partykit)
library(ROCR)
```

***
## EXERCISE ONE  

This data set has 891 observations and 12 columns.  

```{r}
titanic <- read_csv("Titanic.csv")
nrow(titanic)
ncol(titanic)
```

***
## EXERCISE TWO  

```{r}
# Set seed
set.seed(29283)

# Convert Survived and Pclass to factor
titanic$Pclass <- factor(titanic$Pclass)
titanic$Survived <- factor(titanic$Survived)

# Create training set
train_set <- titanic %>% sample_frac(0.7)

# Create test set (observations in titanic$PassengerId that are not in train_set$PassengerId)
test_set <- titanic %>% filter(!(titanic$PassengerId %in% train_set$PassengerId))
```

***
## EXERCISE THREE  

Preliminary to fitting the model...  
* My guess is that Pclass level 2 and 3 are associated with a lower probability of survival than Pclass level 1, Sex (female) is associated with a higher probability of survival ("Women and children first!"), and higher Fares are associated with higher probability of survival.  
* My concern about this choice of features is that Fare and Pclass may be correlated.  

```{r}
# Fit the logistic regression model
log_mod.1 <- glm(Survived ~ Pclass + Sex + Fare, data = train_set, family = "binomial")
# Output coefficients
tidy(log_mod.1)
```

The coefficients in the model show that:  
* The lower class the passenger is, the lower the probability of survival.  
* Being male is associated with a lower probability of survival.  
* Paying a higher fare is associated with a higher probability of survival.  

The p-values of the coefficients show that Pclass and Sex are statistically significant predictors of survival, but Fare is not.

***
## EXERCISE FOUR

a. A third class female passenger who paid a fare >= 23.7 has a low probability of survival.  
b. I'm surprised that the tree shows such different probabilities for survival among third class female passengers depending on what fare they paid. Higher fares do not seem to be associated with higher probability of survival among third class female passengers.  
```{r}
# Fit the decision tree model
tree_mod.1 <- rpart(Survived ~ Pclass + Sex + Fare, data = train_set)
# Visualize the tree
plot(as.party(tree_mod.1))
```

***
## EXERCISE FIVE  

```{r}
# Get the predictions from each model for the test set
test_logit <- predict(log_mod.1, newdata = test_set, type = 'response')
test_tree <- predict(tree_mod.1, newdata = test_set)[,2]
```

a. Plot the ROC curve for each model

```{r}
# Create the prediction objects for both models
pred_logit <- prediction(predictions = test_logit, labels = test_set$Survived)
pred_tree <- prediction(predictions = test_tree, labels = test_set$Survived)

# Get the FPR and TPR for the logistic model
# Recall that the ROC curve plots the FPR on the x-axis
perf_logit <- performance(pred_logit, measure = 'tpr', x.measure = 'fpr')
perf_logit_tbl <- tibble(perf_logit@x.values[[1]], perf_logit@y.values[[1]])

# Change the names of the columns of the tibble
names(perf_logit_tbl) <- c('fpr', 'tpr')

# Get the FPR and TPR for the tree model
perf_tree <- performance(pred_tree, measure = 'tpr', x.measure = 'fpr')
perf_tree_tbl <- tibble(perf_tree@x.values[[1]], perf_tree@y.values[[1]])

# Change the names of the columns of the tibble
names(perf_tree_tbl) <- c('fpr', 'tpr')

# Plotting function for plotting a nice ROC curve using ggplot
plot_roc <- function(perf_tbl) {
  p <- ggplot(data = perf_tbl, aes(x = fpr, y = tpr)) +
  geom_line(color = 'blue') +
  geom_abline(intercept = 0, slope = 1, lty = 3) +
  labs(x = 'False positive rate', y = 'True positive rate') +
  theme_bw()
  return(p)
}

# Create the ROC curves using the function we created above
plot_roc(perf_logit_tbl) + labs(title = 'Logistic Regression Model')
plot_roc(perf_tree_tbl) + labs(title = 'Decision Tree Model')
```

b. The ROC curves appear roughly the same, though the decision tree curve is much smoother.

The AUC calculations show that the models' performances are quite similar, with the logistic regression model slightly better than the decision tree model (AUC = 0.81 vs. AUC = 0.78).

```{r}
# Calculate the AUC
auc_logit <- performance(pred_logit, measure = "auc")
auc_tree <- performance(pred_tree, measure = "auc")

# Extract the AUC value
auc_logit@y.values[[1]]
auc_tree@y.values[[1]]
```

c. At the cutoff value of 0.64 probability, the decision tree model predicts with slightly higher accuracy (77.5%) than the logistic regression model does (75.3%).

```{r}
# Cutoff value = 0.64
test_set <- test_set %>% 
  # Append predicted probabilities from logistic regression model
  mutate(pred_prob_log = test_logit) %>%
  # Append predicted categories (survived Yes or No) from log reg model probabilities
  mutate(pred_cat_log = case_when(pred_prob_log < .64 ~ 'No',
                                   pred_prob_log >= .64 ~ 'Yes')) %>%
  # Append predicted probabilities from decision tree model
  mutate(pred_prob_tree = test_tree) %>% 
  # Append predicted categories (survived Yes or No) from tree model probabilities
  mutate(pred_cat_tree = case_when(pred_prob_tree < .64 ~ 'No',
                                    pred_prob_tree >= .64 ~ 'Yes'))

# Create confusion matrices of each model's predictions
test_set %>% count(pred_cat_log, Survived) %>% spread(Survived, n)
test_set %>% count(pred_cat_tree, Survived) %>% spread(Survived, n)

# Accuracy of logistic regression model's predictions
(156 + 45) / (156 + 45 + 60 + 6)

# Accuracy of decision tree model's predictions
(146 + 61) / (146 + 61 + 44 + 16)
```

***
## EXERCISE SIX

```{r}
# Fit a logistic regression model adding Age as a feature
log_mod.2 <- glm(Survived ~ Pclass + Sex + Fare + Age, data = train_set, 
                 family = "binomial")
# Output coefficients
tidy(log_mod.2)
# Get the predictions for the model
test_logit.2 <- predict(log_mod.2, newdata = test_set, type = 'response')
# Create the prediction object for the model
pred_logit.2 <- prediction(predictions = test_logit.2, labels = test_set$Survived)
# Get the FPR and TPR for the model
perf_logit.2 <- performance(pred_logit.2, measure = 'tpr', x.measure = 'fpr')
perf_logit_tbl.2 <- tibble(perf_logit.2@x.values[[1]], perf_logit.2@y.values[[1]])
# Change the names of the columns of the tibble
names(perf_logit_tbl.2) <- c('fpr', 'tpr')
# Plot the ROC curve
plot_roc(perf_logit_tbl.2) + labs(title = 'Logistic Regression Model 2')
# Calculate AUC
auc_logit.2 <- performance(pred_logit.2, measure = "auc")
# Extract the AUC value
auc_logit.2@y.values[[1]]
```

```{r}
# Fit a decision tree model adding Age as a feature
tree_mod.2 <- rpart(Survived ~ Pclass + Sex + Fare + Age, data = train_set)
# Visualize the tree
plot(as.party(tree_mod.2))
# Get the predictions from the model for the test set
test_tree.2 <- predict(tree_mod.2, newdata = test_set)[,2]
# Create the prediction object for the model
pred_tree.2 <- prediction(predictions = test_tree.2, labels = test_set$Survived)
# Get the FPR and TPR for the model
perf_tree.2 <- performance(pred_tree.2, measure = 'tpr', x.measure = 'fpr')
perf_tree_tbl.2 <- tibble(perf_tree.2@x.values[[1]], perf_tree.2@y.values[[1]])
# Change the names of the columns of the tibble
names(perf_tree_tbl.2) <- c('fpr', 'tpr')
# Plot the ROC curve
plot_roc(perf_tree_tbl.2) + labs(title = 'Decision Tree Model 2')
# Calculate the AUC
auc_tree.2 <- performance(pred_tree.2, measure = "auc")
# Extract the AUC value
auc_tree.2@y.values[[1]]
```

```{r}
# Fit a logistic regression model adding SibSp and Parch as features
log_mod.3 <- glm(Survived ~ Pclass + Sex + Fare + Age + SibSp + Parch, 
                 data = train_set, family = "binomial")
# Output coefficients
tidy(log_mod.3)
# Get the predictions for the model
test_logit.3 <- predict(log_mod.3, newdata = test_set, type = 'response')
# Create the prediction object for the model
pred_logit.3 <- prediction(predictions = test_logit.3, labels = test_set$Survived)
# Get the FPR and TPR for the model
perf_logit.3 <- performance(pred_logit.3, measure = 'tpr', x.measure = 'fpr')
perf_logit_tbl.3 <- tibble(perf_logit.3@x.values[[1]], perf_logit.3@y.values[[1]])
# Change the names of the columns of the tibble
names(perf_logit_tbl.3) <- c('fpr', 'tpr')
# Plot the ROC curve
plot_roc(perf_logit_tbl.3) + labs(title = 'Logistic Regression Model 3')
# Calculate AUC
auc_logit.3 <- performance(pred_logit.3, measure = "auc")
# Extract the AUC value
auc_logit.3@y.values[[1]]
```

```{r}
# Fit a decision tree model adding SibSp and Parch as features
tree_mod.3 <- rpart(Survived ~ Pclass + Sex + Fare + Age + SibSp + Parch, data = train_set)
# Visualize the tree
plot(as.party(tree_mod.3))
# Get the predictions from the model for the test set
test_tree.3 <- predict(tree_mod.3, newdata = test_set)[,2]
# Create the prediction object for the model
pred_tree.3 <- prediction(predictions = test_tree.3, labels = test_set$Survived)
# Get the FPR and TPR for the model
perf_tree.3 <- performance(pred_tree.3, measure = 'tpr', x.measure = 'fpr')
perf_tree_tbl.3 <- tibble(perf_tree.3@x.values[[1]], perf_tree.3@y.values[[1]])
# Change the names of the columns of the tibble
names(perf_tree_tbl.3) <- c('fpr', 'tpr')
# Plot the ROC curve
plot_roc(perf_tree_tbl.3) + labs(title = 'Decision Tree Model 3')
# Calculate the AUC
auc_tree.3 <- performance(pred_tree.3, measure = "auc")
# Extract the AUC value
auc_tree.3@y.values[[1]]
```


